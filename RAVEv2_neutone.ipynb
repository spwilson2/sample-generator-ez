{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spwilson2/sample-generator-ez/blob/main/RAVEv2_neutone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAVE (v2) Training + Export to neutone"
      ],
      "metadata": {
        "id": "_lklstixMAE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About\n",
        "\n",
        "This version of the RAVE notebook was created by Naotake Masuda for [neutone](https://neutone.space/) @ Qosmo loosely based on the [original RAVE notebook](https://colab.research.google.com/drive/1aK8K186QegnWVMAhfnFRofk_Jf7BBUxl?usp=sharing&pli=1#scrollTo=fwb2J-Nxb4po) by Antoine Caillon and [RAVE v2 notebook](https://colab.research.google.com/drive/1ih-gv1iHEZNuGhHPvCHrleLNXvooQMvI?usp=sharing) by Mois√©s Horta.\n",
        "\n",
        "With this version of the RAVE notebook, you can train RAVE models then export it into .nm file for a timbre transfer effect in neutone vst.\n",
        "\n",
        "If you have any questions or comments, feel free to post them in [our discord](https://discord.com/invite/zaUbtyxDRZ). Read more about tips on training RAVE models [on our blog](https://neutone.space/2022/07/15/neural-timbre-transfer-effects-for-neutone/) (descriptions about arguments are mostly for RAVE v1).\n",
        "\n",
        "Also, checkout the [Colab notebook for DDSP+neutone](https://colab.research.google.com/drive/15FuafmtGWEyvTOOQbN1AMIQRhGLy23Pg?usp=sharing). DDSP is more limited in terms of type of sounds it can handle, but it is faster to train."
      ],
      "metadata": {
        "id": "YO1GOepQL9o5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREDITS\n",
        "\n",
        "RAVE algorithm was developed by Antoine Caillon and Philippe Esling, STMS Laboratory (IRCAM, CNRS, Sorbonne University, Ministry of Culture and Communication) and licensed by IRCAM.\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1-1AL6CuNocQnA4wvV3lqsPgU54BKGsQ4' width=\"200\"/>"
      ],
      "metadata": {
        "id": "CZHGEc0BYwQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check GPU\n",
        "\n",
        "Make sure your Colab runtime is using the GPU instead of CPU!\n",
        "\n",
        "To use GPUs:\n",
        "`Menu bar: Runtime->Runtime type->GPU`\n",
        "\n",
        "Now we can check the GPU card with `nvidia-smi`.\n",
        "\n",
        "- V100/A100: GOOD (Colab pro users only, expensive)\n",
        "- Tesla T4: OK"
      ],
      "metadata": {
        "id": "WJbH7z4haHH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "6dI6IN-eaVbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed73e5e-6355-42c3-f578-78fbd898c4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun  7 10:05:39 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install requirements\n",
        "\n"
      ],
      "metadata": {
        "id": "f19NT3RFaVIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L https://repo.anaconda.com/miniconda/Miniconda3-py39_4.12.0-Linux-x86_64.sh -o miniconda.sh\n",
        "!chmod +x miniconda.sh\n",
        "!sh miniconda.sh -b -p /content/miniconda\n",
        "# necessary for data loading\n",
        "!/content/miniconda/bin/conda install -y 'ffmpeg<5'\n",
        "# installing rave to conda environment via pip\n",
        "!/content/miniconda/bin/pip install acids-rave"
      ],
      "metadata": {
        "id": "uou1YCOUCLvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training data\n",
        "\n",
        "Put your audio dataset (a folder containing \"wav\", \"mp3\", \"opus\", \"aac\", \"flac\" files) somewhere in your drive and specify the path to it in `input_dataset` in the settings cell. You can navigate through the drive via the folder icon on the left sidebar (Google Drive content should be under `drive/MyDrive`). By right-clicking on a folder and selecting \"copy path\", you can copy the full path of the folder. Make sure the path doesn't contain any whitespaces!\n",
        "\n",
        "### Tips\n",
        "\n",
        "- Data preprocessing maybe required for good results.\n",
        "    - Gain normalization is necessary if the original data is relatively quiet.\n",
        "        - A model trained on quiet sounds can behave erratically when it is fed loud sounds as input.\n",
        "- Gather a good audio dataset.\n",
        "    - Recording a long solo performance of a certain instrument is effective and often leads to clean results.\n",
        "        - For example, RAVE.drumkit was trained on a large dataset of many performances using a single drum kit.\n",
        "    - Recording environment should ideally be similar across the dataset.\n",
        "    - Some amount of variety in the data is good, but too much variety brings poor results."
      ],
      "metadata": {
        "id": "BaBJbW02clq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings"
      ],
      "metadata": {
        "id": "uf4aq18J2sJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- save_directory\n",
        "    - This is the directory where all the model checkpoints and logs are saved.\n",
        "    - You can also set this to somewhere on your Google Drive (ex. /content/drive/MyDrive) so that it is never lost.\n",
        "        - The log files can become very large (>5 GBs) so the storage limit might be a problem.\n",
        "    \n",
        "- run_name\n",
        "    - The logs and checkpoints are saved under `[save_directory]/runs/[run_name]/`\n",
        "- architecture: \"v2\", \"v1\", \"discrete\", \"onnx\", \"raspberry\"\n",
        "    - v2 corresponds to the new RAVE model, while v1\n",
        "    - See [original repository](https://github.com/acids-ircam/RAVE) for more details\n",
        "- regularization_type: \"default\", \"wasserstein\", \"spherical\"\n",
        "    - different regularization techniques for the v2 model\n",
        "    - See [original repository](https://github.com/acids-ircam/RAVE) for more details\n",
        "- sampling_rate: sampling rate of the model, typically set to 48kHz or 44.1kHz. The plugin will resample when the model is used in other sampling rates.\n",
        "- no_latency_mode: When turned off, output quality is improved but latency of about 0.5s or more will be introduced, which may be undesirable for a vst plugin.\n",
        "- validation_every: This sets the interval for saving model checkpoints."
      ],
      "metadata": {
        "id": "ahfoDaWadn82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "input_dataset = \"/content/drive/MyDrive/AUDIO_FOLDER\"  #@param {type:\"string\"}\n",
        "if ' ' in input_dataset:\n",
        "    print('WARNING: whitespaces not allowed in input dataset path')\n",
        "    # https://github.com/acids-ircam/RAVE/issues/190\n",
        "save_directory = \"/content/RAVEruns/\"  #@param {type:\"string\"}\n",
        "run_name = \"testrun\"  #@param {type:\"string\"}\n",
        "# input_dataset = \"/content/drive/MyDrive/shakuhachi\"  #@param {type:\"string\"}\n",
        "sampling_rate = 48000  #@param {type:\"integer\"}\n",
        "no_latency_mode = True  #@param {type:\"boolean\"}\n",
        "architecture = \"v2\" #@param [\"v2\", \"v1\", \"discrete\", \"onnx\", \"raspberry\" ]\n",
        "regularization_type = \"wasserstein\" #@param [\"default\", \"wasserstein\", \"spherical\"]\n",
        "# regularization_strength = 0.01  #@param {type:\"slider\", min:0.01, max:1, step:0.001}\n",
        "validation_every = 15000  #@param {type:\"integer\"}\n",
        "\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "%cd $save_directory\n",
        "run_name = run_name.replace(\" \", \"_\").lower()\n",
        "preprocess_dir = os.path.join('/content/preprocessed', run_name)\n",
        "os.makedirs(preprocess_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "DW4C7t9zLJtj",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59712e5d-f8dc-4be7-9b71-6eb83ca19ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RAVEruns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start tensorboard\n",
        "\n",
        "Upon first running this cell, you might not see any result. After running the training cell, you can come back to this cell to see the training progress by hitting the refresh button in the top right corner.\n",
        "\n",
        "### Audio\n",
        "\n",
        "You can listen to the reconstruction results in the audio tab. The audio consists of the original segment followed by the model reconstruction. The model reconstruction should sound like the original."
      ],
      "metadata": {
        "id": "tPOYVPFsIH5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir . --bind_all"
      ],
      "metadata": {
        "id": "393NHkX_D1YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Training takes about a day for the first stage (which is 1 million steps, where number of steps = number of epochs * number of batches in the dataset), and 3 days or more for the second stage (depends on your GPU). You can cut off training anytime if the reconstruction results sound good enough for you.\n",
        "\n",
        "First, every audio file present in your input_dataset folder are resampled to the target sampling rate and compiled in a database file under `content/preprocessed/[run_name]/` with `rave preprocess` command. Then the rave\n",
        "\n",
        "### Colab limitations\n",
        "\n",
        "Since there are limits to how long you can keep a Colab notebook open, this cell will be disconnected during training. If so, you can run this cell again (or if that doesn't work, start from the top cell) to resume training from where it was before getting cut off.\n",
        "There are [some tricks](https://stackoverflow.com/questions/57113226/how-to-prevent-google-colab-from-disconnecting) to prevent disconnection.\n",
        "\n",
        "On free tiers for Colab, you might hit a limit of GPU time per month during training. Colab pro (\\$9.99/mo) or pro+ (\\$49.99) may be required for training more models."
      ],
      "metadata": {
        "id": "XWzP_KRbJszt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train from scratch"
      ],
      "metadata": {
        "id": "_SJtFcZik1N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/miniconda/bin/rave preprocess --input_path $input_dataset --output_path $preprocess_dir --sampling_rate $sampling_rate\n",
        "train_arg = f\"\"\"--config {architecture} --config {regularization_type} \\\n",
        "--db_path {preprocess_dir} --name {run_name} --val_every {validation_every} \\\n",
        "--override SAMPLING_RATE={sampling_rate}\"\"\"\n",
        "if no_latency_mode:\n",
        "    train_arg += \" --config causal\"\n",
        "!/content/miniconda/bin/rave train $train_arg"
      ],
      "metadata": {
        "id": "BG4klfUqiJDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ...or resume training"
      ],
      "metadata": {
        "id": "yMFkKEbLktCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VL6Je_dlxDt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nmp4_9DoxECb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CspsQtB8xKxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Find Last run\n",
        "\n",
        "Use the next cell to find the last saved checkpoint or find it manually from the left sidebar.\n"
      ],
      "metadata": {
        "id": "Bk_SPwU4k61z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, itertools, time\n",
        "used_save_dir = \"/content/RAVEruns\" #@param {type:\"string\"}\n",
        "used_run_name = \"testrun\" #@param {type:\"string\"}\n",
        "runs_dir = os.path.join(used_save_dir, 'runs')\n",
        "ckpts = [glob.glob(os.path.join(runs_dir, d, '**', '*.ckpt'), recursive=True) for d in os.listdir(runs_dir) if d.startswith(used_run_name)]\n",
        "ckpts = list(itertools.chain.from_iterable(ckpts))\n",
        "if len(ckpts)>0:\n",
        "    latest_ckpt = max(ckpts, key=os.path.getctime)\n",
        "    print(f'Latest ckpt is: {latest_ckpt}')\n",
        "    print(f'at {time.ctime(os.path.getctime(latest_ckpt))} (UTC)')\n",
        "else:\n",
        "    print('No checkpoint found')"
      ],
      "metadata": {
        "id": "0WJaC_F6xSls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resume training\n",
        "\n",
        "Make sure you run the settings cell (above) with the same settings used during previous training. Fill in `resume_ckpt` with the path to the checkpoint to resume from."
      ],
      "metadata": {
        "id": "cBSVReve6f5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resume_ckpt = \"PATH/TO/CHECKPOINT\" #@param {type:\"string\"}\n",
        "!/content/miniconda/bin/rave preprocess --input_path $input_dataset --output_path $preprocess_dir --sampling_rate $sampling_rate\n",
        "train_arg = f\"\"\"--config {architecture} --config {regularization_type} \\\n",
        "--db_path {preprocess_dir} --name {run_name} --val_every {validation_every} --ckpt {resume_ckpt} \\\n",
        "--override SAMPLING_RATE={sampling_rate}\"\"\"\n",
        "if no_latency_mode:\n",
        "    train_arg += \" --config causal\"\n",
        "!/content/miniconda/bin/rave train $train_arg"
      ],
      "metadata": {
        "id": "UYgsxy3wkREB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export to neutone\n",
        "\n",
        "Once you're done training, you can export to torchscript (.ts) then neutone model format (.nm).\n",
        "If you're growing impatient or don't have the time, you can pause training and export mid-training.\n",
        "\n",
        "`final_res_folder`: folder containing model versions and config.gin file (ex. `/content/drive/MyDrive/RAVEruns/runs/RUNNAME_2b26dfad3c`)"
      ],
      "metadata": {
        "id": "Va8g9OIhqkRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install neutone to Colab runtime\n",
        "!pip install neutone_sdk torch==1.13.1"
      ],
      "metadata": {
        "id": "Gmkl4Y44HXdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export to torchscript first\n",
        "final_res_folder = \"/content/RAVEruns/runs/testrun_cfefbe3eab\" #@param {type:\"string\"}\n",
        "!/content/miniconda/bin/rave export --run $final_res_folder --streaming true"
      ],
      "metadata": {
        "id": "rrYQZ7qCD3Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define RAVEModel Wrapper\n",
        "\n",
        "Edit in information about your model in `get_model_name`, `get_model_authors`, etc."
      ],
      "metadata": {
        "id": "zUPMfg_4kQlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from neutone_sdk import WaveformToWaveformBase, NeutoneParameter\n",
        "from neutone_sdk.utils import load_neutone_model, save_neutone_model\n",
        "\n",
        "\n",
        "class RAVEModelWrapper(WaveformToWaveformBase):\n",
        "    def get_model_name(self) -> str:\n",
        "        return \"RAVE.example\"  # <-EDIT THIS\n",
        "\n",
        "    def get_model_authors(self) -> List[str]:\n",
        "        return [\"Author Name\"]  # <-EDIT THIS\n",
        "\n",
        "    def get_model_short_description(self) -> str:\n",
        "        return \"RAVE model trained on xxx sounds.\"  # <-EDIT THIS\n",
        "\n",
        "    def get_model_long_description(self) -> str:\n",
        "        return (  # <-EDIT THIS\n",
        "            \"RAVE timbre transfer model trained on xxx sounds. Useful for xxx sounds.\"\n",
        "        )\n",
        "\n",
        "    def get_technical_description(self) -> str:\n",
        "        return \"RAVE model proposed by Caillon, Antoine et al.\"\n",
        "\n",
        "    def get_technical_links(self) -> Dict[str, str]:\n",
        "        return {\n",
        "            \"Paper\": \"https://arxiv.org/abs/2111.05011\",\n",
        "            \"Code\": \"https://github.com/acids-ircam/RAVE\",\n",
        "        }\n",
        "\n",
        "    def get_tags(self) -> List[str]:\n",
        "        return [\"timbre transfer\", \"RAVE\"]\n",
        "\n",
        "    def get_model_version(self) -> str:\n",
        "        return \"1.0.0\"\n",
        "\n",
        "    def is_experimental(self) -> bool:\n",
        "        \"\"\"\n",
        "        set to True for models in experimental stage\n",
        "        (status shown on the website)\n",
        "        \"\"\"\n",
        "        return True  # <-EDIT THIS\n",
        "\n",
        "    def get_neutone_parameters(self) -> List[NeutoneParameter]:\n",
        "        return [\n",
        "            NeutoneParameter(\n",
        "                name=\"Chaos\", description=\"Magnitude of latent noise\", default_value=0.0\n",
        "            ),\n",
        "            NeutoneParameter(\n",
        "                name=\"Z edit index\",\n",
        "                description=\"Index of latent dimension to edit\",\n",
        "                default_value=0.0,\n",
        "            ),\n",
        "            NeutoneParameter(\n",
        "                name=\"Z scale\",\n",
        "                description=\"Scale of latent variable\",\n",
        "                default_value=0.5,\n",
        "            ),\n",
        "            NeutoneParameter(\n",
        "                name=\"Z offset\",\n",
        "                description=\"Offset of latent variable\",\n",
        "                default_value=0.5,\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "    def is_input_mono(self) -> bool:\n",
        "        return False  # <-Set to False for stereo (each channel processed separately)\n",
        "\n",
        "    def is_output_mono(self) -> bool:\n",
        "        return False  # <-Set to False for stereo (each channel processed separately)\n",
        "\n",
        "    def get_native_sample_rates(self) -> List[int]:\n",
        "        return [48000]  # <-EDIT THIS\n",
        "\n",
        "    def get_native_buffer_sizes(self) -> List[int]:\n",
        "        return [2048]\n",
        "\n",
        "    def get_citation(self) -> str:\n",
        "        return \"\"\"Caillon, A., & Esling, P. (2021). RAVE: A variational autoencoder for fast and high-quality neural audio synthesis. arXiv preprint arXiv:2111.05011.\"\"\"\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def do_forward_pass(self, x: Tensor, params: Dict[str, Tensor]) -> Tensor:\n",
        "        # parameters edit the latent variable\n",
        "        z = self.model.encode(x.unsqueeze(1))\n",
        "        noise_amp = params[\"Chaos\"]\n",
        "        z = torch.randn_like(z) * noise_amp + z\n",
        "        # add offset / scale\n",
        "        idx_z = int(\n",
        "            torch.clamp(params[\"Z edit index\"], min=0.0, max=0.99)\n",
        "            * self.model.latent_size\n",
        "        )\n",
        "        z_scale = params[\"Z scale\"] * 2  # 0~1 -> 0~2\n",
        "        z_offset = params[\"Z offset\"] * 2 - 1  # 0~1 -> -1~1\n",
        "        z[:, idx_z] = z[:, idx_z] * z_scale + z_offset\n",
        "        out = self.model.decode(z)\n",
        "        out = out.squeeze(1)\n",
        "        return out  # (n_channels=1, sample_size)"
      ],
      "metadata": {
        "id": "1HL-q4fqmCMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "ts_files = glob.glob(os.path.join(final_res_folder, '*.ts'))\n",
        "ts_file = max(ts_files, key=os.path.getctime)\n",
        "# Load model and wrap\n",
        "model = torch.jit.load(ts_file)\n",
        "wrapper = RAVEModelWrapper(model)\n",
        "audio_sample_pairs=None"
      ],
      "metadata": {
        "id": "MyFqH0rHHwJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Audio sample paths for example input\n",
        "#@markdown These will be used as an example input/output pair to be saved with the model.\n",
        "#@markdown This doesn't matter if you're using the models locally.\n",
        "#@markdown Leave these empty to use default.\n",
        "\n",
        "from neutone_sdk.audio import (\n",
        "    AudioSample,\n",
        "    AudioSamplePair,\n",
        "    render_audio_sample,\n",
        ")\n",
        "import torchaudio\n",
        "\n",
        "example_input1 = '' #@param {type:\"string\"}\n",
        "example_input2 = '' #@param {type:\"string\"}\n",
        "example_inputs = [example_input1, example_input2]\n",
        "\n",
        "if example_input1 == '' and example_input2 == '':\n",
        "    audio_sample_pairs=None\n",
        "else:\n",
        "    audio_sample_pairs=[]\n",
        "    for sound_path in example_inputs:\n",
        "        wave, sr = torchaudio.load(sound_path)\n",
        "        wave = wave.mean(0, keepdim=True)\n",
        "        input_sample = AudioSample(wave, sr)\n",
        "        rendered_sample = render_audio_sample(wrapper, input_sample)\n",
        "        audio_sample_pairs.append(AudioSamplePair(input_sample, rendered_sample))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eEC3hNhmHtcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save neutone model\n",
        "neutone_save_dir = '/content/drive/MyDrive/neutone/' #@param {type:\"string\"}\n",
        "save_neutone_model(\n",
        "        wrapper, Path(neutone_save_dir) / run_name, freeze=False, dump_samples=True, submission=True, audio_sample_pairs=audio_sample_pairs\n",
        ")"
      ],
      "metadata": {
        "id": "JurAnXfJIR-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use model in neutone!\n",
        "\n",
        "You can download the .nm file from Google Drive (under `{neutone_save_dir}`) and load it in neutone (via the \"load your own\" button at the top of the model selection screen)\n",
        "\n",
        "If you're satisfied with your model, consider submitting to us via Github (link is in the output of save_neutone_model) or showing it off in the [neutone discord](https://discord.com/invite/zaUbtyxDRZ)!\n"
      ],
      "metadata": {
        "id": "KRoFvP9EK6z5"
      }
    }
  ]
}